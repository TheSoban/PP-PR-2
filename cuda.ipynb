{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e520ba33",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import cupy as cp\n",
    "from numba import cuda, int64\n",
    "from timeit import default_timer as timer\n",
    "import simple\n",
    "\n",
    "cuda.select_device(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea34b9d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df(times: list[int], samples: int):\n",
    "    if len(times) < samples - 2:\n",
    "        return \"----\"\n",
    "    return str(round((np.sum(times) - min(times) - max(times)) / (samples - 2) * 1000, 2)).replace(\".\",\",\")\n",
    "\n",
    "def comp_tracks(offset: np.array, track: np.array) -> int:\n",
    "    return np.sum(np.abs(np.subtract(offset, track)))\n",
    "\n",
    "def calc_cpu(offset: np.array, track: np.array) -> int:\n",
    "    return np.argmin(np.array([\n",
    "        comp_tracks(offset, track[i:(i + 1024)]) for i in range(len(track) - 1024)]))\n",
    "\n",
    "@cuda.jit(device=True)\n",
    "def diff(a, b):\n",
    "    return abs(a - b)\n",
    "\n",
    "@cuda.jit\n",
    "def calc_gpu(offset, track, res):\n",
    "    off = cuda.blockIdx.x + cuda.blockIdx.y * cuda.gridDim.y\n",
    "    t_idx = cuda.threadIdx.x + cuda.threadIdx.y * cuda.blockDim.y\n",
    "\n",
    "    if off >= res.shape[0] or t_idx >= track.shape[0]:\n",
    "        return\n",
    "\n",
    "    res[off, t_idx] = diff(offset[t_idx], track[off + t_idx])\n",
    "\n",
    "@cuda.jit\n",
    "def calc_gpu_shared(offset, track, res):\n",
    "    off = cuda.blockIdx.x + cuda.blockIdx.y * cuda.gridDim.y\n",
    "    t_idx = cuda.threadIdx.x + cuda.threadIdx.y * cuda.blockDim.y\n",
    "\n",
    "    if off >= res.shape[0] or t_idx >= track.shape[0]:\n",
    "        return\n",
    "\n",
    "    sharedMem = cuda.shared.array(shape=(1), dtype=int64)\n",
    "    if t_idx == 0:\n",
    "        sharedMem[0] = 0\n",
    "    \n",
    "    cuda.syncthreads()\n",
    "    cuda.atomic.add(sharedMem, 0, diff(offset[t_idx], track[off + t_idx]))\n",
    "    cuda.syncthreads()\n",
    "\n",
    "    if t_idx == 0:\n",
    "        res[off] = sharedMem[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de3a545",
   "metadata": {},
   "outputs": [],
   "source": [
    "original = simple.load_sound_files()[0]\n",
    "original.skip_samples(10000)\n",
    "test_data = { int(size): { \"offset\": original.data[1024:2048], \"track\": original.data[:int(size)], \"noise\": original.noise[:int(size)] } for size in [5e3, 1e4, 2e4, 5e4, 1e5, 2e5, 5e5]}\n",
    "\n",
    "data = test_data[10000]\n",
    "tmp = [comp_tracks(data[\"offset\"], data[\"track\"][i:(i + 1024)]) for i in range(len(data[\"track\"]) - 1024)]\n",
    "tmp_n = [comp_tracks(data[\"offset\"], data[\"noise\"][i:(i + 1024)]) for i in range(len(data[\"noise\"]) - 1024)]\n",
    "\n",
    "plt.plot(range(len(data[\"track\"]) - 1024), tmp) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c44e81",
   "metadata": {},
   "source": [
    "## Vanilla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70683b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = 12\n",
    "results = {}\n",
    "\n",
    "for size, data in test_data.items():\n",
    "    times = []\n",
    "    for i in range(samples):\n",
    "        start = timer()\n",
    "        res = calc_cpu(data[\"offset\"], data[\"track\"])\n",
    "        end = timer()\n",
    "        if res != 1024:\n",
    "            print(f\"Bad value for size: {size}\")\n",
    "            break;\n",
    "        times.append(end - start)\n",
    "    print(f\"{size:>8} = {get_df(times, samples):>8}ms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ece63fd",
   "metadata": {},
   "source": [
    "## Vanilla with noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c8b2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = 12\n",
    "results = {}\n",
    "\n",
    "for size, data in test_data.items():\n",
    "    times = []\n",
    "    for i in range(samples):\n",
    "        start = timer()\n",
    "        res = calc_cpu(data[\"offset\"], data[\"noise\"])\n",
    "        end = timer()\n",
    "        if res != 1024:\n",
    "            print(res)\n",
    "            print(f\"Bad value for size: {size}\")\n",
    "            break;\n",
    "        times.append(end - start)\n",
    "    print(f\"{size:>8} = {get_df(times, samples):>8}ms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "561203be",
   "metadata": {},
   "source": [
    "## CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00cb5e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "threads_per_block = (32, 32)\n",
    "block_size = int(np.ceil(np.sqrt(original.len - 1024)))\n",
    "blocks_per_grid = (block_size, block_size)\n",
    "\n",
    "samples = 13\n",
    "\n",
    "for size, data in test_data.items():\n",
    "    times = []\n",
    "    for i in range(samples):\n",
    "        start = timer()\n",
    "        offset_gpu = cuda.to_device(data[\"offset\"])\n",
    "        track_gpu = cuda.to_device(data[\"track\"])\n",
    "        res_gpu = cuda.to_device(np.zeros((len(data[\"track\"]) - 1024, 1024), dtype=np.int16))\n",
    "        calc_gpu[blocks_per_grid, threads_per_block](offset_gpu, track_gpu, res_gpu)\n",
    "        arg = np.argmin(np.sum(res_gpu.copy_to_host(), axis=1))\n",
    "        end = timer()\n",
    "        if i == 0:\n",
    "            continue\n",
    "\n",
    "        if res_gpu != 1024:\n",
    "            print(f\"Bad value for size: {size}\")\n",
    "            break;\n",
    "        times.append(end - start)\n",
    "    print(f\"{size:>8} = {get_df(times, samples - 1):>8}ms\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8afc92a2",
   "metadata": {},
   "source": [
    "## CUDA with noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f45365",
   "metadata": {},
   "outputs": [],
   "source": [
    "threads_per_block = (32, 32)\n",
    "block_size = int(np.ceil(np.sqrt(original.len - 1024)))\n",
    "blocks_per_grid = (block_size, block_size)\n",
    "\n",
    "samples = 13\n",
    "\n",
    "for size, data in test_data.items():\n",
    "    times = []\n",
    "    for i in range(samples):\n",
    "        start = timer()\n",
    "        offset_gpu = cuda.to_device(data[\"offset\"])\n",
    "        track_gpu = cuda.to_device(data[\"noise\"])\n",
    "        res_gpu = cuda.to_device(np.zeros((len(data[\"noise\"]) - 1024, 1024), dtype=np.int16))\n",
    "        calc_gpu[blocks_per_grid, threads_per_block](offset_gpu, track_gpu, res_gpu)\n",
    "        arg = np.argmin(np.sum(res_gpu.copy_to_host(), axis=1))\n",
    "        end = timer()\n",
    "        if i == 0:\n",
    "            continue\n",
    "\n",
    "        if res_gpu != 1024:\n",
    "            print(f\"Bad value for size: {size}\")\n",
    "            break;\n",
    "        times.append(end - start)\n",
    "    print(f\"{size:>8} = {get_df(times, samples - 1):>8}ms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ffeef6",
   "metadata": {},
   "source": [
    "## CUDA with shared memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c4ada0",
   "metadata": {},
   "outputs": [],
   "source": [
    "threads_per_block = (32, 32)\n",
    "block_size = int(np.ceil(np.sqrt(original.len - 1024)))\n",
    "blocks_per_grid = (block_size, block_size)\n",
    "\n",
    "samples = 4\n",
    "\n",
    "for size, data in test_data.items():\n",
    "    times = []\n",
    "    for i in range(samples):\n",
    "        start = timer()\n",
    "        offset_gpu = cuda.to_device(data[\"offset\"])\n",
    "        track_gpu = cuda.to_device(data[\"track\"])\n",
    "        res_gpu = cuda.to_device(np.zeros((len(data[\"track\"]) - 1024), dtype=np.int16))\n",
    "        calc_gpu_shared[blocks_per_grid, threads_per_block](offset_gpu, track_gpu, res_gpu)\n",
    "        arg = np.argmin(res_gpu.copy_to_host())\n",
    "        end = timer()\n",
    "        if i == 0:\n",
    "            continue\n",
    "\n",
    "        if res != 1024:\n",
    "            print(f\"Bad value for size: {size}\")\n",
    "            break;\n",
    "        times.append(end - start)\n",
    "    print(f\"{size:>8} = {get_df(times, samples - 1):>8}ms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f868da",
   "metadata": {},
   "source": [
    "## FFT comperasion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e3ec0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = 50\n",
    "\n",
    "print(\"CPU\")\n",
    "for size, data in test_data.items():\n",
    "    times = []\n",
    "    for i in range(sample_size):\n",
    "        start = timer()\n",
    "        np.fft.fft(data[\"track\"])\n",
    "        end = timer()\n",
    "        times.append(end - start)\n",
    "    print(f\"{size:>8} = {get_df(times, sample_size):>8}ms\")\n",
    "\n",
    "print(\"GPU\")\n",
    "for size, data in test_data.items():\n",
    "    times = []\n",
    "    for i in range(sample_size):\n",
    "        start = timer()\n",
    "        cp.fft.fft(cp.array(data[\"track\"])).get()\n",
    "        end = timer()\n",
    "        times.append(end - start)\n",
    "    print(f\"{size:>8} = {get_df(times, sample_size):>8}ms\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "4fbfea1dd5a17f80dff8df3ba641602c59e31ce1a55b82aea18e6894ff3c71a7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
